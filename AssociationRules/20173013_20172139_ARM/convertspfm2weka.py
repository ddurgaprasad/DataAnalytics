# -*- coding: utf-8 -*-
"""ConvertSPFM2WEKA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_O-Mxm2KkYhxnSVsjlTdbP0AY2i8ImGr
"""

import numpy as np
import pandas as pd

"""# Load SPFM data and conver it to Panda dataframe"""

# Commented out IPython magic to ensure Python compatibility.
# %%sh
# wget http://www.philippe-fournier-viger.com/spmf/datasets/SIGN.txt

spfm_data='SIGN.txt'

#Read SPFM raw data
f = open(spfm_data, 'r+')
raw_lines = [line.strip() for line in f.readlines()]
f.close()

#Seperator is -1 and -2 is end of line -->convert into CSV 
itemset_dict={}
i=0
max_cols=0
for line in raw_lines:
  itemset=[int(item.strip()) for item in line.split('-1')[:-1] ]
  itemset_dict[i]=itemset
  if max_cols < len(itemset):
    max_cols=len(itemset)
  i=i+1

#Make each row of same number of columns by padding zeros upto max_columns
from itertools import repeat
for key in itemset_dict:
  itemset_dict[key].extend(repeat('?', max_cols - len(itemset_dict[key])))

len(itemset_dict[1])

itemset_list=[]
for key in itemset_dict:
  itemset_list.append(itemset_dict[key])

df=pd.DataFrame(np.array(itemset_list))

df.head()

my_corpus=[]
for line in raw_lines:
  itemset=[int(item.strip()) for item in line.split('-1')[:-1] ]
  my_string = ','.join(str(x) for x in itemset)
  my_corpus.append(my_string)

"""**Itemsets of all transactions together**"""

from sklearn.feature_extraction.text import CountVectorizer
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(my_corpus)
print(vectorizer.get_feature_names())

df=pd.DataFrame(data=X.toarray(), columns=vectorizer.get_feature_names())

df.head()

df[df==0] = '?'
df[df==1] ='t'

df.head()

"""**Create 'arff' format suitbale to load in WEKA**"""

import shutil
import os

att_file=open('Header.txt','w')
att_file.write("@relation    "  + spfm_data.split('.')[0])
att_file.write('\n')

for att in vectorizer.get_feature_names():
  att_new='\''+att+'\''
  my_str='@attribute '+att_new+ ' { t}'
  att_file.write(my_str)
  att_file.write('\n')
att_file.write('@data')
att_file.write('\n')  
att_file.close()  

df.to_csv('Data.csv',index=False,header=False)

target_filename=spfm_data.split('.')[0]+".arff"


with open(target_filename,'wb') as wfd:
    for f in ['Header.txt','Data.csv']:
        with open(f,'rb') as fd:
            shutil.copyfileobj(fd, wfd)
os.remove('Header.txt')  
os.remove('Data.csv')