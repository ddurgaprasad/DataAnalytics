# -*- coding: utf-8 -*-
"""Clustering_Football.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NVvOX8KIJvdMIg_40TgC-yVLRNRSawxV
"""

import os
if not os.path.exists("/content/football_data.csv"):
    os.symlink("/content/drive/My Drive/DataAnalytics/Clustering_Football/football_data.csv","/content/football_data.csv")

"""# **Load Data and view samples**"""

import pandas as pd
import numpy as np

df=pd.read_csv('football_data.csv')
df.head()

"""The number of rows and columns."""

df.shape,df.columns

"""Display the last five rows"""

pd.set_option("display.max.columns", None)
df.tail()

"""Display all columns and their data types"""

df.info()

"""**Basics Statistics**"""

df.describe()

"""# **Data Cleaning**

Drop columns that are not useful
"""

df.columns

drop_columns=['Unnamed: 0', 'ID', 'Photo', 'Flag', 'Club Logo','Real Face', 'Special', 'Joined', 'Loaned From', 'Contract Valid Until','Release Clause']
df.drop(drop_columns, 1,inplace=True)

pd.set_option("display.max.columns", None)
df.tail()

"""Convert age from string to float"""

def isNaN(num):
    return num != num

def set_ht(ht):
  
  if isNaN(ht):
      return None
  # format: 7' 0.0"
  ht=str(ht)+'\"'
  ht_ = ht.split("'")
  ft_ = float(ht_[0])
  in_ = float(ht_[1].replace("\"",""))

  return (12*ft_) + in_

df["Height"]=df["Height"].apply(lambda x:set_ht(x))

df.head()

# Handle missing values
df['Height'].fillna(5.10, inplace = True)

df["Height"].head()

"""Clean weight column ,drop lbs and convert from string to float"""

def set_wt(wt):
  
  if isNaN(wt):
      return None
  return float(wt.replace('lbs',''))

# Handle missing values
df["Weight"]=df["Weight"].apply(lambda x:set_wt(x))

df["Weight"].head()

df['Weight'].isna().sum()

#Check and update if there are nulls
print(df['Weight'].isna().sum())
df['Weight'].fillna(df['Weight'].mean(), inplace = True)
print(df['Weight'].isna().sum())
df.Weight.head()

"""Convert ['Value', 'Wage','Release Clause'] in string format to float in Euros

1.   M stands for millions
2.   K stands for Thousands
3.   Apply multiplication factor accordingly




*   Check if value is number or float or na
*   Update value accordingly
"""

# Defining a function for cleaning the wage column
def set_euro_value(val):

    if type(val) == float:
      return val 

    if isNaN(val):
      return None    
    val = val.replace('â‚¬', '')
    
    if 'M' in val:
        #Million
        val = float(val.replace('M', ''))*1000000
    elif 'K' in val:
        #Thousand
        val = float(val.replace('K', ''))*1000
    return float(val)

for col in ['Value', 'Wage']:
  df[col]=df[col].apply(lambda x:set_euro_value(x))

for col in ['Value', 'Wage']:
  print(col)
  print(df[col].head())

#Check and update if there are nulls
print(df['Value'].isna().sum())

df['Value'].fillna(df['Value'].mode(), inplace = True)
print(df['Value'].isna().sum())
df.Value.head()

#Check and update if there are nulls
print(df['Wage'].isna().sum())

df['Wage'].fillna(df['Wage'].mode(), inplace = True)
print(df['Wage'].isna().sum())
df.Value.head()

df.Nationality.unique()

df['Work Rate'].fillna('Medium/ Medium', inplace = True)
df['Skill Moves'].fillna(df['Skill Moves'].median(), inplace = True)
df['Weak Foot'].fillna(3, inplace = True)
df['Preferred Foot'].fillna('Right', inplace = True)
df['International Reputation'].fillna(1, inplace = True)

"""# 1. Data visualisation"""

# Commented out IPython magic to ensure Python compatibility.
import seaborn as sns
sns.set(style="whitegrid")
from collections import Counter
# %matplotlib inline
import warnings
warnings.filterwarnings('ignore')

"""Plot of heights of the players"""

from matplotlib import pyplot as plt
f, ax = plt.subplots(figsize=(8,6))
x = df.Height
x = pd.Series(x, name="Height of player in inches")
ax = sns.kdeplot(x, shade=True, color='g')
plt.show()

"""Number of left or right foot players"""

f, ax = plt.subplots(figsize=(8, 6))
sns.countplot(x="Preferred Foot", data=df, palette = 'GnBu')
plt.show()

"""Top ten countries in wages earned"""

df_countries=df.nlargest(10, 'Wage')
plt.figure(figsize=(20,12))
chart=sns.catplot(x='Nationality', y='Wage', hue="Potential", kind="bar", palette='Set1', dodge=False,data=df_countries)
chart.set_xticklabels(rotation=45)

"""Finding Youngest and oldest players"""

df_age=df.nlargest(10, 'Age')
df_age=df_age[['Name', 'Age', 'Nationality']]
df_age.style.background_gradient('inferno')

df_age=df.nsmallest(10, 'Age')
df_age=df_age[['Name', 'Age', 'Nationality']]
df_age.style.background_gradient('inferno')

"""Top ten players by their market value"""

sns.set(style="white")
plt.figure(figsize=(11,8))
df_value=df.nlargest(10, 'Value')
p = sns.boxplot(x = 'Club', y = 'Value', data = df_value)
p = sns.boxplot(x = 'Name', y = 'Value', data = df_value)
p = plt.xticks(rotation=90)

"""England players with their market value based on their field position"""

sns.set(style="white")
plt.figure(figsize=(20,12))

df_england =df[df['Nationality']=='England']

chart=sns.catplot(x='Position', y='Wage', hue="Value", kind="bar", palette='Set1', dodge=False,data=df_england)
chart.set_xticklabels(rotation=90)
chart._legend.remove()

"""Outlier detection using box plot

Observations outside the whiskers are outliers and are drawn as circles.
"""

import seaborn as sns
#sns.jointplot(x='Name', y='Potential', data = df_value)

chart=sns.boxplot(x = 'Name', y = 'Potential', data = df)
chart.set_xticklabels(rotation=90)

!pip install geopandas



"""# **Additional Data Cleaning after Visualization**"""

df['Work Rate'].head().unique()

"""**Drop non-numerical data as required per instruction**"""

numerical_cols = [cname for cname in df.columns if  df[cname].dtype in ['int64', 'float64']]

# Keep selected columns only
X_data = df[numerical_cols].copy()
X_data.shape

"""**Drop na values and check the samples**"""

X_data.dropna(inplace=True)
X_data.shape
X_data.head()

"""**Verify is there are any missing vlues**"""

X_data.isnull().sum()

"""**Normalize all the columns**"""

from sklearn.preprocessing import normalize
X_data = normalize(X_data)

"""1. Pick number of clusters k 
1. Max itertions for algorithm to keep an upper bound
1. Acceptable tolerancw beyond which two samples are trated as different
"""

k=2
max_iterations=100
tolerance=0.0001

"""**Distance Metrics**"""

def getEuclideanDistance(point, centroid):
    return np.linalg.norm(point-centroid)

def getManhattanDistance(point, centroid):
    return np.sum(np.abs(point-centroid))

def getCosineDistance(point, centroid):
    return np.dot(point,centroid)

getEuclideanDistance(np.array([1,0]),np.array([0,1]))

"""**Intialize k random points from given data as centroids**"""

from random import randint

def initRandomCentroids(X,k):
  rows,cols=X.shape
  centroids=[X[np.random.choice(0,rows)]  for i in range(k)]  
  return centroids

"""**Function to find closest centroid**"""

def getNearestCentroidIndex(point, centroids): 
      distances = [getEuclideanDistance(point, centroid) for centroid in centroids]     
      return distances.index(min(distances)) # returns index of nearest point

"""**Find the distance between the current point and the cluster**"""

def createNewClusters(X,centroids,k):	
  #Find closest centroid for each data sample.Associate with index
  clusters=[[] for i in range(k)]
  for current_sample in X:		    		
    centroid_index = getNearestCentroidIndex(current_sample, centroids)
    clusters[centroid_index].append(current_sample)
    return clusters

"""**Recompute the centroids of new clsuters**"""

def RecalculateCentroids(X,clusters):
	centroids=[np.average(X[cluster], axis=0) for cluster in clusters]
	return centroids

"""**Get labels of the clsuters**"""

def getLabels(clusters, X):
  y_pred = np.zeros(len(X))
  for i, cluster in enumerate(clusters):
    for j in cluster:
      y_pred[j] = i
  return y_pred

"""**Predict the labels**"""

def fit(X,k,max_iterations):

  #Intitilize k centroids
	centroids = initRandomCentroids(X,k)

  #Repeat until convergence or terminate at max_iterations
	for i in range(max_iterations):
		#Create clusters
		clusters = createNewClusters(X,centroids, k)
		# Save current centroids
		old_centroids = centroids
		# Calculate new centroids
		centroids = RecalculateCentroids(clusters,X)
		# If no centroids have changed => convergence
		diff = centroids - old_centroids
		if not diff.any():
			break

	return getLabels(clusters, X)

k=2
max_iterations=100
tolerance=0.0001

y_pred = fit(X_data,k,max_iterations)

def initRandomCentroids(X,k):
  rows,cols=X.shape
  centroids = {}
  for i in range(k):
    centroids[i]=x[randint(0,rows)]
  return centroids 

def fit(X_data):
	centroids=initRandomCentroids(X,k)
	for i in range(max_iter):
		labels = {}
		for i in range(k):
			labels[i]=[]

		for sample in X_data:
			label=getNearestCentroidIndex(sample,centroid)
      labels[label]=np.average(labels[label,axis=0)

for sample in X_data:      
 			classification = getNearestCentroidIndex(sample,centroid)
      classifications[classification].append(sample)
      
      prev_centroids = dict(centroids)

		for classification in classifications:
			centroids[classification] = np.average(classifications[classification],axis=0)

		optimized = True

		for c in centroids:
			original_centroid = prev_centroids[c]
			current_centroid = centroids[c]
			if np.sum((current_centroid-original_centroid)/original_centroid*100.0) > tol:
				print(np.sum((current_centroid-original_centroid)/original_centroid*100.0))
				optimized = False

		if optimized:
			break

def predict(X_data):
	distances = [np.linalg.norm(X_data-centroids[centroid]) for centroid in centroids]
	classification = distances.index(min(distances))
	return classification